#!/bin/bash
#SBATCH -A uot256
#SBATCH --job-name="Word count"
#SBATCH --output="wordcount.distr.out"
#SBATCH --partition=compute
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=4
#SBATCH --mem=16G
#SBATCH --export=ALL 
#SBATCH --time=29

export HADOOP_CONF_DIR=/home/$USER/expansecluster
module load cpu/0.15.4 gcc/7.5.0 openjdk

SW=/expanse/lustre/projects/uot182/fegaras
export HADOOP_HOME=$SW/hadoop-3.2.2
export MYHADOOP_HOME=$SW/myhadoop
PATH="$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$MYHADOOP_HOME/bin:$PATH"

myhadoop-configure.sh -s /scratch/$USER/job_$SLURM_JOBID -i "s/$/.ib.cluster/"

cp $HADOOP_CONF_DIR/slaves $HADOOP_CONF_DIR/workers

start-all.sh

hdfs dfs -rm -r /user/$USER/*
hdfs dfs -mkdir -p /user/$USER

hdfs dfs -put wc-input.txt /user/$USER/wc-input.txt

hadoop jar WordCount.jar WordCount /user/$USER/wc-input.txt /user/$USER/output

rm -rf output-distr
mkdir output-distr

hdfs dfs -get /user/$USER/output/* output-distr

stop-all.sh
myhadoop-cleanup.sh
